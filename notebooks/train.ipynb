{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T14:20:36.248398Z",
     "start_time": "2020-06-15T14:20:35.380019Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T14:20:36.267321Z",
     "start_time": "2020-06-15T14:20:36.258607Z"
    }
   },
   "outputs": [],
   "source": [
    "class AspectCNN(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 word_embed,\n",
    "                 aspect_input,\n",
    "                 kernel_num=200,\n",
    "                 kernel_sizes=[3, 4],\n",
    "                 n_class=4):\n",
    "        super(AspectCNN, self).__init__()\n",
    "\n",
    "        ############## 相关参数 #############\n",
    "        # 词嵌入\n",
    "        self.word_embed = word_embed\n",
    "        self.vocab_size, self.embed_dim = word_embed.shape\n",
    "\n",
    "        # 角度向量，每个角度都由一组单词组成\n",
    "        # 角度嵌入，20个角度，每个角度表示成一个向量，然后可以分成四类\n",
    "        # 如角度：位置，分成四类：方便、普通、不方便、未提及\n",
    "        # 如角度：口味，分成四类：好吃、普通、难吃、未提及\n",
    "        self.aspect_input = aspect_input\n",
    "        self.num_aspects, _ = aspect_input.shape\n",
    "\n",
    "        # CNN处理参数\n",
    "        self.kernel_num = kernel_num\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "\n",
    "        # 四分类\n",
    "        self.n_class = n_class\n",
    "\n",
    "        ############### 相关层 #########################\n",
    "        self.word_embedings = tf.keras.layers.Embedding(\n",
    "            self.vocab_size, self.embed_dim, weights=[self.word_embed])\n",
    "\n",
    "        self.aspect_fc = tf.keras.layers.Dense(self.kernel_num)\n",
    "\n",
    "        self.convs4word = [\n",
    "            tf.keras.layers.Conv1D(filters=self.kernel_num,\n",
    "                                   kernel_size=k,\n",
    "                                   activation='tanh')\n",
    "            for k in self.kernel_sizes\n",
    "        ]\n",
    "\n",
    "        self.convs4aspect = [\n",
    "            tf.keras.layers.Conv1D(filters=self.kernel_num,\n",
    "                                   kernel_size=k,\n",
    "                                   activation=None) for k in self.kernel_sizes\n",
    "        ]\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(self.n_class, activation='softmax')\n",
    "\n",
    "    def get_aspect_embed(self):\n",
    "        # num_aspects,aspect_words,embed_size\n",
    "        aspects_embed = self.word_embedings(self.aspect_input)\n",
    "\n",
    "        # num_aspects,embed_size\n",
    "        aspects_embed = tf.reduce_mean(aspects_embed, axis=1)\n",
    "        return aspects_embed\n",
    "\n",
    "    def call(self, input_text):\n",
    "        batch_size = input_text.shape[0]\n",
    "        feature = self.word_embedings(input_text)  # batch,seq_len,embed_size\n",
    "        aspects_embed = self.get_aspect_embed()  # num_aspects,embed_size\n",
    "        aspects = self.aspect_fc(aspects_embed)  # num_aspects,kernel_num\n",
    "        aspects = tf.expand_dims(aspects, 1)  # num_aspects,1,kernel_num\n",
    "\n",
    "        x = [tf.expand_dims(conv(feature), 1) for conv in self.convs4word]\n",
    "        # batch, 1, seq_len-k+1, kernel_num\n",
    "\n",
    "        y = [\n",
    "            tf.nn.relu(tf.expand_dims(conv(feature), 1) + aspects)\n",
    "            for conv in self.convs4aspect\n",
    "        ]\n",
    "        # batch, num_aspects, seq_len-k+1, kernel_num\n",
    "\n",
    "        x0 = [i * j for i, j in zip(x, y)]\n",
    "        x0 = [tf.reshape(t, tf.constant((-1, *t.shape[2:]))) for t in x0]\n",
    "        x0 = [\n",
    "            tf.squeeze(tf.nn.max_pool1d(t, t.shape[1], 1, padding='VALID'), 1)\n",
    "            for t in x0\n",
    "        ]\n",
    "\n",
    "        shape = np.array([batch_size, self.num_aspects,\n",
    "                            self.kernel_num]).astype(np.int32)\n",
    "        x0 = [tf.reshape(t, shape) for t in x0]\n",
    "        x0 = tf.concat(x0, 2)\n",
    "        return self.fc(x0)  # batch,num_aspects,n_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T14:20:40.431741Z",
     "start_time": "2020-06-15T14:20:38.759188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 7, 4)\n"
     ]
    }
   ],
   "source": [
    "word_embed = tf.constant(np.random.randn(20, 8), dtype=tf.float32)\n",
    "aspect_input = tf.constant(np.random.randint(2, 15, (7, 5)), dtype=tf.int32)\n",
    "kernel_num = 11\n",
    "\n",
    "model = AspectCNN(word_embed, aspect_input, kernel_num=kernel_num)\n",
    "\n",
    "input_text = tf.constant(np.random.randint(1, 15, (2, 1113)), dtype=tf.int32)\n",
    "res = model(input_text)\n",
    "print(res.shape)  # 2, 7, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T14:20:43.953836Z",
     "start_time": "2020-06-15T14:20:43.879111Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127528"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_path = \"./datasets/vocab.txt\"\n",
    "word2id = {}\n",
    "with open(vocab_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines[1:]:\n",
    "        word, idx = line.split()\n",
    "        idx = int(idx)\n",
    "        word2id[word] = idx\n",
    "len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T14:20:45.583371Z",
     "start_time": "2020-06-15T14:20:44.903700Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('./datasets/datasets.npy','rb') as f:\n",
    "    train_dataset = np.load(f)\n",
    "    val_dataset = np.load(f)\n",
    "    test_dataset = np.load(f)\n",
    "    \n",
    "with open('./datasets/labels.npy','rb') as f:\n",
    "    train_labels = np.load(f)\n",
    "    train_ws = np.load(f)\n",
    "    \n",
    "    val_labels = np.load(f)\n",
    "    val_ws = np.load(f)\n",
    "\n",
    "\n",
    "word_embed = np.load('./saved/word_embed.npy')\n",
    "\n",
    "aspect_input = np.load(\"./datasets/aspects.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T14:20:48.800801Z",
     "start_time": "2020-06-15T14:20:48.794884Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((105000, 20, 4), (105000, 1113), (20, 7), (15000, 1113))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape, train_dataset.shape, aspect_input.shape, val_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T14:20:50.376614Z",
     "start_time": "2020-06-15T14:20:50.024007Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices(\n",
    "    (train_dataset, train_labels, train_ws)).shuffle(buffer_size=1024)\n",
    "train_data = train_data.batch(32).prefetch(\n",
    "    buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "val_data = tf.data.Dataset.from_tensor_slices(\n",
    "    (val_dataset, val_labels, val_ws)).shuffle(buffer_size=1024)\n",
    "val_data = val_data.batch(32).prefetch(\n",
    "    buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T14:20:52.094585Z",
     "start_time": "2020-06-15T14:20:51.763885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 1113)\n"
     ]
    }
   ],
   "source": [
    "for datas, labels, wts in train_data.take(1):\n",
    "    print(datas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T14:20:52.793748Z",
     "start_time": "2020-06-15T14:20:52.787977Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3281.25, 468.75)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "105000/32, 15000/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T14:20:53.819970Z",
     "start_time": "2020-06-15T14:20:53.813895Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20, 7), dtype=int32, numpy=\n",
       "array([[  1,   2,   3,   4,   5,   6,   7],\n",
       "       [  8,   9,  10,  11,  12,  13,  14],\n",
       "       [ 15,   4,  16,  17,  18,   3,  19],\n",
       "       [ 20,  21,  22,  23,  24,  25,  26],\n",
       "       [ 27,  28,  29,  30,  31,  32,  33],\n",
       "       [ 34,  35,  36,  37,  38,  39,  40],\n",
       "       [ 41,  42,  43,  44,  45,  46,  22],\n",
       "       [ 47,  48,  49,  50,  51,  52,  53],\n",
       "       [ 54,  55,  56,  57,  58,  53,  59],\n",
       "       [ 60,  61,  62,  63,  64,  65,  66],\n",
       "       [ 67,  68,  69,  70,  71,  72,  73],\n",
       "       [ 74,  75,  67,  76,  77,  78,  79],\n",
       "       [ 80,  81,  82,  83,  67,  84,  85],\n",
       "       [ 86,  87,  75,  88,  89,  90,  91],\n",
       "       [ 92,  93,  94,  95,  96,  97,  98],\n",
       "       [ 99, 100,  90, 101, 102, 103, 104],\n",
       "       [105, 106, 107, 108, 109, 110, 111],\n",
       "       [112, 113, 114, 115, 116, 117, 118],\n",
       "       [119, 120, 121, 122, 123, 124, 125],\n",
       "       [126, 127, 128, 129, 130, 114, 112]], dtype=int32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspect_input = tf.constant(aspect_input, dtype=tf.int32)\n",
    "aspect_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T14:23:29.264178Z",
     "start_time": "2020-06-15T14:23:29.257782Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T14:23:30.015082Z",
     "start_time": "2020-06-15T14:23:30.004705Z"
    }
   },
   "outputs": [],
   "source": [
    "model = AspectCNN(word_embed, aspect_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T14:23:30.900155Z",
     "start_time": "2020-06-15T14:23:30.893338Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T14:23:32.745007Z",
     "start_time": "2020-06-15T14:23:32.739832Z"
    }
   },
   "outputs": [],
   "source": [
    "subjects_eng = [\n",
    "    'location_traffic_convenience',\n",
    "    'location_distance_from_business_district',\n",
    "    'location_easy_to_find',\n",
    "    'service_wait_time',\n",
    "    'service_waiters_attitude',\n",
    "    'service_parking_convenience',\n",
    "    'service_serving_speed',\n",
    "    'price_level',\n",
    "    'price_cost_effective',\n",
    "    'price_discount',\n",
    "    'environment_decoration',\n",
    "    'environment_noise',\n",
    "    'environment_space',\n",
    "    'environment_cleaness',\n",
    "    'dish_portion',\n",
    "    'dish_taste',\n",
    "    'dish_look',\n",
    "    'dish_recommendation',\n",
    "    'others_overall_experience',\n",
    "    'others_willing_to_consume_again',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T14:23:33.561585Z",
     "start_time": "2020-06-15T14:23:33.557147Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-15T14:23:35.827Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 :\n",
      "Starting Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [01:01,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 200 on Training :\n",
      "Traning Loss : 0.14493535459041595\n",
      "Total_f1=0.31272046566029144,\n",
      " f1_details=[0.418 0.484 0.279 0.305 0.263 0.323 0.317 0.244 0.299 0.198 0.487 0.386\n",
      " 0.255 0.198 0.152 0.379 0.209 0.305 0.534 0.219]\n",
      "Total_acc=0.7203125,\n",
      " acc_details=[0.719 0.938 0.719 0.844 0.5   0.938 0.906 0.531 0.812 0.656 0.719 0.781\n",
      " 0.594 0.656 0.438 0.688 0.719 0.844 0.625 0.781]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [02:02,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 400 on Training :\n",
      "Traning Loss : 0.1188097819685936\n",
      "Total_f1=0.47216504171490364,\n",
      " f1_details=[0.733 0.458 0.233 0.483 0.502 1.    0.279 0.354 0.214 0.673 0.589 0.548\n",
      " 0.362 0.74  0.34  0.443 0.272 0.292 0.448 0.48 ]\n",
      "Total_acc=0.75625,\n",
      " acc_details=[0.938 0.844 0.875 0.906 0.625 1.    0.719 0.625 0.75  0.844 0.812 0.844\n",
      " 0.688 0.75  0.438 0.594 0.688 0.781 0.781 0.625]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600it [03:04,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 600 on Training :\n",
      "Traning Loss : 0.11638867855072021\n",
      "Total_f1=0.49113048466625353,\n",
      " f1_details=[0.536 0.571 0.714 0.399 0.47  1.    0.242 0.439 0.219 0.399 0.809 0.45\n",
      " 0.396 0.378 0.395 0.413 0.547 0.229 0.59  0.623]\n",
      "Total_acc=0.7796875,\n",
      " acc_details=[0.875 0.812 0.875 0.875 0.719 1.    0.906 0.625 0.781 0.719 0.875 0.75\n",
      " 0.688 0.781 0.562 0.625 0.781 0.844 0.75  0.75 ]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "800it [04:03,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 800 on Training :\n",
      "Traning Loss : 0.1177515834569931\n",
      "Total_f1=0.49387181762462673,\n",
      " f1_details=[0.935 0.817 0.423 0.317 0.595 0.323 0.483 0.577 0.344 0.672 0.428 0.407\n",
      " 0.35  0.294 0.491 0.699 0.36  0.305 0.661 0.395]\n",
      "Total_acc=0.8046875,\n",
      " acc_details=[0.969 0.875 0.875 0.906 0.75  0.938 0.906 0.719 0.75  0.938 0.812 0.875\n",
      " 0.656 0.656 0.656 0.719 0.719 0.844 0.812 0.719]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:03,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 1000 on Training :\n",
      "Traning Loss : 0.09738887846469879\n",
      "Total_f1=0.6084994949860086,\n",
      " f1_details=[0.96  0.857 0.921 0.487 0.632 0.323 0.532 0.642 0.782 0.597 0.449 0.54\n",
      " 0.544 0.465 0.552 0.409 0.47  0.839 0.579 0.592]\n",
      "Total_acc=0.8296875,\n",
      " acc_details=[0.969 0.938 0.938 0.906 0.844 0.938 0.875 0.688 0.812 0.812 0.844 0.812\n",
      " 0.812 0.656 0.656 0.594 0.844 0.906 0.875 0.875]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1200it [06:05,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 1200 on Training :\n",
      "Traning Loss : 0.07681073248386383\n",
      "Total_f1=0.7322176464418793,\n",
      " f1_details=[0.945 0.869 0.66  0.366 0.719 1.    1.    0.8   0.904 0.836 0.621 0.905\n",
      " 0.629 0.629 0.569 0.533 0.533 0.896 0.636 0.593]\n",
      "Total_acc=0.8703125,\n",
      " acc_details=[0.969 0.906 0.969 0.906 0.812 1.    1.    0.844 0.938 0.875 0.875 0.875\n",
      " 0.812 0.812 0.75  0.812 0.812 0.875 0.844 0.719]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1400it [07:07,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 1400 on Training :\n",
      "Traning Loss : 0.09013751894235611\n",
      "Total_f1=0.5828573190591991,\n",
      " f1_details=[0.945 0.881 0.605 0.487 0.829 0.556 0.496 0.698 0.504 0.517 0.425 0.594\n",
      " 0.401 0.39  0.544 0.709 0.534 0.299 0.374 0.87 ]\n",
      "Total_acc=0.8421875,\n",
      " acc_details=[0.969 0.938 0.938 0.875 0.844 0.969 0.938 0.719 0.781 0.812 0.812 0.938\n",
      " 0.781 0.812 0.719 0.75  0.781 0.812 0.781 0.875]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1600it [08:09,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 1600 on Training :\n",
      "Traning Loss : 0.10763680934906006\n",
      "Total_f1=0.6144107624446411,\n",
      " f1_details=[0.488 0.531 0.702 0.404 0.496 1.    0.64  0.609 0.572 0.706 0.762 0.455\n",
      " 0.538 0.742 0.425 0.933 0.536 0.809 0.528 0.414]\n",
      "Total_acc=0.81875,\n",
      " acc_details=[0.938 0.875 0.906 0.875 0.75  1.    0.906 0.656 0.875 0.812 0.844 0.688\n",
      " 0.625 0.781 0.562 0.906 0.875 0.875 0.812 0.812]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1800it [09:11,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 1800 on Training :\n",
      "Traning Loss : 0.09361407905817032\n",
      "Total_f1=0.5767172911496936,\n",
      " f1_details=[0.647 0.477 0.667 0.233 0.613 1.    0.403 0.755 0.579 0.374 0.843 0.769\n",
      " 0.557 0.868 0.57  0.4   0.633 0.371 0.403 0.374]\n",
      "Total_acc=0.8359375,\n",
      " acc_details=[0.969 0.812 0.969 0.844 0.844 1.    0.875 0.812 0.844 0.625 0.906 0.844\n",
      " 0.875 0.906 0.781 0.75  0.844 0.812 0.688 0.719]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [10:12,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 2000 on Training :\n",
      "Traning Loss : 0.08557746559381485\n",
      "Total_f1=0.6871544046492877,\n",
      " f1_details=[0.744 0.855 0.782 0.492 0.815 0.556 0.657 0.768 0.806 0.802 0.537 0.889\n",
      " 0.647 0.565 0.339 0.842 0.416 0.957 0.807 0.469]\n",
      "Total_acc=0.859375,\n",
      " acc_details=[0.969 0.906 0.875 0.938 0.875 0.969 0.906 0.812 0.844 0.875 0.812 0.844\n",
      " 0.75  0.781 0.719 0.844 0.75  0.969 0.875 0.875]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2200it [11:14,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 2200 on Training :\n",
      "Traning Loss : 0.09479258954524994\n",
      "Total_f1=0.6359481531984311,\n",
      " f1_details=[0.855 0.8   0.458 0.579 0.406 0.825 0.526 0.879 0.223 0.602 0.931 0.758\n",
      " 0.613 0.665 0.839 0.561 0.317 0.809 0.641 0.432]\n",
      "Total_acc=0.825,\n",
      " acc_details=[0.875 0.844 0.906 0.938 0.625 0.969 0.844 0.875 0.781 0.812 0.906 0.844\n",
      " 0.781 0.844 0.812 0.719 0.656 0.875 0.781 0.812]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2400it [12:15,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 2400 on Training :\n",
      "Traning Loss : 0.08304129540920258\n",
      "Total_f1=0.6883009485113487,\n",
      " f1_details=[0.909 0.88  0.793 0.322 0.795 0.6   0.741 0.651 1.    0.589 0.693 0.724\n",
      " 0.531 0.623 0.607 0.643 0.549 0.904 0.562 0.65 ]\n",
      "Total_acc=0.8640625,\n",
      " acc_details=[0.938 0.906 0.875 0.906 0.844 0.969 0.938 0.719 1.    0.875 0.875 0.781\n",
      " 0.812 0.875 0.812 0.781 0.781 0.938 0.844 0.812]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2600it [13:17,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 2600 on Training :\n",
      "Traning Loss : 0.08944612741470337\n",
      "Total_f1=0.641522942237791,\n",
      " f1_details=[0.607 0.506 0.789 0.649 0.582 1.    0.574 0.906 0.756 0.624 0.426 0.66\n",
      " 0.489 0.556 0.673 0.497 0.463 0.881 0.322 0.87 ]\n",
      "Total_acc=0.8390625,\n",
      " acc_details=[0.906 0.781 0.844 0.906 0.781 1.    0.906 0.875 0.906 0.844 0.812 0.844\n",
      " 0.688 0.844 0.75  0.719 0.812 0.969 0.688 0.906]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2800it [14:18,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 2800 on Training :\n",
      "Traning Loss : 0.06999306380748749\n",
      "Total_f1=0.6928548905549,\n",
      " f1_details=[0.641 0.477 0.633 0.656 0.688 0.494 0.839 0.749 0.383 0.76  0.785 0.815\n",
      " 0.867 0.62  0.536 0.845 0.92  0.5   0.672 0.978]\n",
      "Total_acc=0.875,\n",
      " acc_details=[0.969 0.812 0.938 0.938 0.812 0.938 0.938 0.75  0.781 0.812 0.844 0.906\n",
      " 0.875 0.875 0.781 0.812 0.969 0.875 0.906 0.969]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [15:19,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 3000 on Training :\n",
      "Traning Loss : 0.09432177245616913\n",
      "Total_f1=0.6296176072248496,\n",
      " f1_details=[0.604 0.498 0.571 0.857 0.698 0.246 0.592 0.831 0.827 0.508 0.602 0.837\n",
      " 0.683 0.488 0.677 0.804 0.423 0.782 0.602 0.462]\n",
      "Total_acc=0.846875,\n",
      " acc_details=[0.906 0.812 0.844 0.938 0.875 0.938 0.844 0.906 0.938 0.75  0.875 0.875\n",
      " 0.781 0.75  0.781 0.781 0.781 0.906 0.781 0.875]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3200it [16:21,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 3200 on Training :\n",
      "Traning Loss : 0.07448405027389526\n",
      "Total_f1=0.6691290084496152,\n",
      " f1_details=[0.904 0.65  0.822 0.711 0.56  1.    0.542 0.665 0.582 0.672 0.728 0.912\n",
      " 0.62  0.705 0.444 0.47  0.473 0.415 0.619 0.888]\n",
      "Total_acc=0.8515625,\n",
      " acc_details=[0.938 0.906 0.938 0.875 0.75  1.    0.938 0.812 0.875 0.75  0.844 0.906\n",
      " 0.844 0.906 0.688 0.719 0.812 0.844 0.844 0.844]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3282it [16:46,  3.26it/s]\n",
      "3it [00:00, 29.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Starting Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:16, 28.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, on Validation :\n",
      "Total_f1=0.6647500000000001, \n",
      " f1_details=[0.782 0.708 0.675 0.543 0.729 0.718 0.665 0.711 0.677 0.671 0.665 0.68\n",
      " 0.669 0.663 0.636 0.637 0.496 0.695 0.616 0.659]\n",
      "Total_acc=0.8515625, \n",
      " acc_details=[0.942 0.883 0.906 0.897 0.837 0.971 0.92  0.771 0.881 0.829 0.841 0.851\n",
      " 0.807 0.852 0.773 0.754 0.789 0.889 0.799 0.839]\n",
      "================================================================================\n",
      "Epoch 1 :\n",
      "Starting Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [01:01,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 200 on Training :\n",
      "Traning Loss : 0.09515146911144257\n",
      "Total_f1=0.5656080203146513,\n",
      " f1_details=[0.468 0.563 0.661 0.397 0.519 0.461 0.578 0.715 0.633 0.604 0.731 0.859\n",
      " 0.611 0.875 0.473 0.51  0.37  0.408 0.428 0.45 ]\n",
      "Total_acc=0.83125,\n",
      " acc_details=[0.938 0.875 0.969 0.812 0.781 0.906 0.875 0.781 0.938 0.812 0.75  0.875\n",
      " 0.719 0.844 0.688 0.781 0.781 0.844 0.781 0.875]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [02:02,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 400 on Training :\n",
      "Traning Loss : 0.09300617128610611\n",
      "Total_f1=0.6442732712877564,\n",
      " f1_details=[0.543 0.5   0.418 0.533 0.755 0.6   0.76  0.645 0.75  0.575 0.513 0.667\n",
      " 0.833 0.589 0.633 0.798 0.388 0.694 0.717 0.976]\n",
      "Total_acc=0.825,\n",
      " acc_details=[0.875 0.875 0.844 0.875 0.812 0.969 0.906 0.719 0.875 0.781 0.75  0.75\n",
      " 0.812 0.719 0.812 0.719 0.781 0.844 0.812 0.969]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600it [03:03,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 600 on Training :\n",
      "Traning Loss : 0.08566387742757797\n",
      "Total_f1=0.6107592389593236,\n",
      " f1_details=[0.892 0.759 0.458 0.352 0.645 0.446 0.332 0.796 0.581 0.679 0.728 0.816\n",
      " 0.775 0.446 0.675 0.356 0.484 0.653 0.624 0.719]\n",
      "Total_acc=0.8515625,\n",
      " acc_details=[0.969 0.906 0.906 0.812 0.781 0.938 0.844 0.844 0.906 0.75  0.844 0.938\n",
      " 0.812 0.844 0.781 0.688 0.75  0.906 0.875 0.938]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "800it [04:04,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 800 on Training :\n",
      "Traning Loss : 0.08296192437410355\n",
      "Total_f1=0.6665662677209548,\n",
      " f1_details=[0.569 0.537 0.661 0.58  0.789 0.595 0.483 0.759 0.657 0.75  0.863 0.611\n",
      " 0.597 0.889 0.714 0.477 0.654 0.763 0.782 0.6  ]\n",
      "Total_acc=0.859375,\n",
      " acc_details=[0.875 0.844 0.906 0.906 0.844 0.906 0.875 0.812 0.875 0.812 0.875 0.906\n",
      " 0.812 0.906 0.781 0.688 0.938 0.875 0.906 0.844]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:06,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1000 on Training :\n",
      "Traning Loss : 0.07374420017004013\n",
      "Total_f1=0.6956969963603745,\n",
      " f1_details=[0.956 0.835 0.689 0.757 0.822 0.5   0.691 0.843 0.628 0.718 0.577 0.815\n",
      " 0.579 0.786 0.65  0.538 0.401 1.    0.583 0.543]\n",
      "Total_acc=0.86875,\n",
      " acc_details=[0.969 0.906 0.906 0.906 0.906 0.969 0.938 0.844 0.938 0.812 0.781 0.812\n",
      " 0.812 0.812 0.812 0.812 0.812 1.    0.812 0.812]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1200it [06:07,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1200 on Training :\n",
      "Traning Loss : 0.09474185854196548\n",
      "Total_f1=0.625545293255313,\n",
      " f1_details=[0.622 0.88  0.713 0.487 0.845 0.512 0.497 0.71  0.777 0.791 0.557 0.642\n",
      " 0.863 0.682 0.744 0.32  0.391 0.594 0.443 0.441]\n",
      "Total_acc=0.8265625,\n",
      " acc_details=[0.938 0.906 0.938 0.812 0.875 0.906 0.844 0.781 0.875 0.844 0.844 0.719\n",
      " 0.875 0.844 0.781 0.625 0.812 0.781 0.719 0.812]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1400it [07:08,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1400 on Training :\n",
      "Traning Loss : 0.07588838040828705\n",
      "Total_f1=0.6405247649846587,\n",
      " f1_details=[0.798 0.881 0.745 0.461 0.647 0.542 0.733 0.7   0.423 0.53  0.529 0.756\n",
      " 0.697 0.682 0.788 0.625 0.47  0.816 0.655 0.332]\n",
      "Total_acc=0.846875,\n",
      " acc_details=[0.906 0.938 0.969 0.844 0.812 0.906 0.938 0.812 0.781 0.781 0.781 0.844\n",
      " 0.844 0.812 0.844 0.875 0.906 0.938 0.688 0.719]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1600it [08:09,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1600 on Training :\n",
      "Traning Loss : 0.05762707069516182\n",
      "Total_f1=0.7069286387120461,\n",
      " f1_details=[1.    0.55  0.816 0.544 0.64  1.    0.825 0.873 1.    0.711 0.64  0.576\n",
      " 0.472 0.536 0.572 0.618 0.507 0.763 0.683 0.811]\n",
      "Total_acc=0.8796875,\n",
      " acc_details=[1.    0.938 0.938 0.938 0.812 1.    0.969 0.875 1.    0.875 0.938 0.906\n",
      " 0.938 0.781 0.75  0.625 0.875 0.875 0.781 0.781]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1800it [09:11,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 1800 on Training :\n",
      "Traning Loss : 0.06286308914422989\n",
      "Total_f1=0.7804925258297813,\n",
      " f1_details=[0.835 0.714 1.    0.81  0.739 1.    0.533 0.677 0.916 0.646 0.725 0.859\n",
      " 0.816 0.942 0.725 0.684 0.583 0.619 0.836 0.948]\n",
      "Total_acc=0.890625,\n",
      " acc_details=[0.906 0.875 1.    0.938 0.812 1.    0.906 0.75  0.906 0.875 0.938 0.906\n",
      " 0.906 0.969 0.75  0.875 0.875 0.844 0.844 0.938]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [10:12,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2000 on Training :\n",
      "Traning Loss : 0.0728532001376152\n",
      "Total_f1=0.6545812582762855,\n",
      " f1_details=[0.592 0.817 0.748 0.455 0.811 0.328 0.566 0.688 0.634 0.806 0.464 0.904\n",
      " 0.739 0.628 0.629 0.798 0.461 0.653 0.8   0.572]\n",
      "Total_acc=0.8578125,\n",
      " acc_details=[0.906 0.875 0.875 0.906 0.844 0.938 0.906 0.781 0.906 0.844 0.875 0.938\n",
      " 0.875 0.938 0.719 0.844 0.75  0.906 0.812 0.719]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2200it [11:13,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2200 on Training :\n",
      "Traning Loss : 0.08519592881202698\n",
      "Total_f1=0.6738285014745531,\n",
      " f1_details=[1.    0.833 0.973 0.371 0.797 0.25  1.    0.819 0.541 0.55  0.592 0.793\n",
      " 0.606 0.79  0.534 0.929 0.411 0.332 0.65  0.705]\n",
      "Total_acc=0.8546875,\n",
      " acc_details=[1.    0.875 0.969 0.906 0.812 0.938 1.    0.844 0.781 0.812 0.812 0.875\n",
      " 0.75  0.906 0.562 0.906 0.812 0.781 0.844 0.906]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2400it [12:14,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2400 on Training :\n",
      "Traning Loss : 0.08683165907859802\n",
      "Total_f1=0.6744511411803443,\n",
      " f1_details=[1.    0.634 0.686 0.233 0.631 0.6   0.491 0.731 0.5   0.807 0.977 0.782\n",
      " 0.717 0.8   0.619 0.697 0.888 0.571 0.477 0.65 ]\n",
      "Total_acc=0.8421875,\n",
      " acc_details=[1.    0.938 0.938 0.844 0.719 0.969 0.906 0.781 0.812 0.906 0.969 0.875\n",
      " 0.781 0.781 0.688 0.719 0.844 0.812 0.719 0.844]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2600it [13:16,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2600 on Training :\n",
      "Traning Loss : 0.06595534831285477\n",
      "Total_f1=0.7154462456578626,\n",
      " f1_details=[0.897 0.714 0.963 0.946 0.934 0.556 0.826 0.614 0.763 0.591 0.649 0.722\n",
      " 0.84  0.907 0.532 0.833 0.45  0.791 0.424 0.356]\n",
      "Total_acc=0.86875,\n",
      " acc_details=[0.938 0.875 0.969 0.969 0.938 0.969 0.938 0.75  0.875 0.781 0.938 0.938\n",
      " 0.906 0.875 0.781 0.844 0.75  0.844 0.75  0.75 ]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2800it [14:17,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 2800 on Training :\n",
      "Traning Loss : 0.08573657274246216\n",
      "Total_f1=0.6682224404719194,\n",
      " f1_details=[0.66  0.931 0.681 0.582 0.81  0.371 0.653 0.613 0.911 0.791 0.622 0.645\n",
      " 0.527 0.844 0.502 0.751 0.682 0.629 0.645 0.513]\n",
      "Total_acc=0.846875,\n",
      " acc_details=[0.969 0.938 0.906 0.875 0.812 0.906 0.906 0.75  0.969 0.844 0.75  0.781\n",
      " 0.719 0.875 0.75  0.781 0.875 0.906 0.875 0.75 ]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [15:18,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 3000 on Training :\n",
      "Traning Loss : 0.08267971873283386\n",
      "Total_f1=0.748303080031816,\n",
      " f1_details=[1.    0.87  0.806 0.617 0.848 1.    0.486 0.729 0.641 0.912 0.557 0.62\n",
      " 0.658 0.801 0.792 0.903 0.478 0.948 0.592 0.708]\n",
      "Total_acc=0.8703125,\n",
      " acc_details=[1.    0.906 0.906 0.906 0.844 1.    0.875 0.75  0.781 0.906 0.781 0.844\n",
      " 0.906 0.906 0.812 0.906 0.688 0.938 0.844 0.906]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3200it [16:19,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 3200 on Training :\n",
      "Traning Loss : 0.07682044059038162\n",
      "Total_f1=0.7197623517200353,\n",
      " f1_details=[0.626 0.857 0.694 0.496 0.815 1.    0.867 0.515 0.859 0.801 0.849 0.726\n",
      " 0.742 0.954 0.617 0.614 0.517 0.628 0.325 0.894]\n",
      "Total_acc=0.8625,\n",
      " acc_details=[0.938 0.938 0.938 0.938 0.875 1.    0.969 0.688 0.906 0.812 0.875 0.844\n",
      " 0.812 0.938 0.719 0.75  0.812 0.906 0.719 0.875]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3282it [16:44,  3.27it/s]\n",
      "3it [00:00, 28.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Starting Validation:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469it [00:16, 28.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, on Validation :\n",
      "Total_f1=0.6717000000000001, \n",
      " f1_details=[0.79  0.725 0.693 0.533 0.735 0.744 0.663 0.721 0.677 0.678 0.671 0.68\n",
      " 0.678 0.662 0.644 0.646 0.507 0.686 0.635 0.666]\n",
      "Total_acc=0.8625, \n",
      " acc_details=[0.944 0.879 0.906 0.886 0.831 0.973 0.912 0.782 0.882 0.826 0.842 0.841\n",
      " 0.803 0.845 0.766 0.761 0.778 0.886 0.804 0.84 ]\n",
      "================================================================================\n",
      "Epoch 2 :\n",
      "Starting Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [01:00,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Step 200 on Training :\n",
      "Traning Loss : 0.08003251254558563\n",
      "Total_f1=0.634646281274026,\n",
      " f1_details=[1.    0.763 0.667 0.658 0.684 1.    0.589 0.45  0.678 0.788 0.381 0.737\n",
      " 0.535 0.523 0.746 0.708 0.362 0.463 0.587 0.375]\n",
      "Total_acc=0.840625,\n",
      " acc_details=[1.    0.875 0.906 0.938 0.844 1.    0.938 0.688 0.875 0.844 0.656 0.906\n",
      " 0.781 0.781 0.844 0.75  0.75  0.812 0.812 0.812]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [02:02,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Step 400 on Training :\n",
      "Traning Loss : 0.0667823776602745\n",
      "Total_f1=0.7464498152025658,\n",
      " f1_details=[0.592 0.768 0.787 0.662 0.888 1.    0.883 0.932 0.967 0.572 0.892 0.67\n",
      " 0.53  0.724 0.703 0.599 0.437 0.601 0.901 0.821]\n",
      "Total_acc=0.8703125,\n",
      " acc_details=[0.906 0.812 0.906 0.938 0.906 1.    0.969 0.938 0.969 0.75  0.906 0.875\n",
      " 0.75  0.938 0.812 0.812 0.562 0.906 0.938 0.812]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600it [03:03,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Step 600 on Training :\n",
      "Traning Loss : 0.06677158176898956\n",
      "Total_f1=0.6538704226068867,\n",
      " f1_details=[0.892 0.857 0.879 0.483 0.792 0.333 0.705 0.633 0.727 0.552 0.819 0.444\n",
      " 0.504 0.416 0.325 0.929 0.423 0.822 0.758 0.784]\n",
      "Total_acc=0.865625,\n",
      " acc_details=[0.969 0.938 0.938 0.906 0.844 0.969 0.938 0.781 0.969 0.781 0.844 0.812\n",
      " 0.781 0.812 0.719 0.875 0.781 0.969 0.812 0.875]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "800it [04:04,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Step 800 on Training :\n",
      "Traning Loss : 0.068959541618824\n",
      "Total_f1=0.7002274330363458,\n",
      " f1_details=[0.94  0.834 0.978 0.625 0.818 0.322 0.817 0.485 0.588 0.49  0.673 0.682\n",
      " 0.931 0.594 0.769 0.971 0.488 0.617 0.801 0.584]\n",
      "Total_acc=0.878125,\n",
      " acc_details=[0.938 0.938 0.969 0.938 0.906 0.875 0.906 0.719 0.906 0.688 0.812 0.906\n",
      " 0.969 0.844 0.812 0.969 0.781 0.938 0.875 0.875]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [05:05,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Step 1000 on Training :\n",
      "Traning Loss : 0.07655569911003113\n",
      "Total_f1=0.724098418432773,\n",
      " f1_details=[0.881 0.782 0.722 1.    0.9   0.5   0.658 0.732 0.766 0.93  0.768 0.902\n",
      " 0.485 0.61  0.75  0.72  0.362 0.857 0.524 0.633]\n",
      "Total_acc=0.8890625,\n",
      " acc_details=[0.938 0.844 0.938 1.    0.969 0.969 0.938 0.812 0.875 0.938 0.875 0.875\n",
      " 0.75  0.906 0.844 0.812 0.812 0.906 0.875 0.906]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1200it [06:07,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Step 1200 on Training :\n",
      "Traning Loss : 0.06900061666965485\n",
      "Total_f1=0.7162517609058618,\n",
      " f1_details=[0.592 0.855 0.865 0.237 0.791 0.716 1.    0.833 0.878 0.597 0.662 0.728\n",
      " 0.929 0.564 0.491 0.858 0.267 0.877 0.867 0.718]\n",
      "Total_acc=0.8703125,\n",
      " acc_details=[0.906 0.906 0.875 0.875 0.875 0.938 1.    0.844 0.906 0.844 0.781 0.844\n",
      " 0.969 0.875 0.719 0.875 0.719 0.938 0.875 0.844]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1332it [06:47,  3.24it/s]"
     ]
    }
   ],
   "source": [
    "aspect_nums = aspect_input.shape[0]\n",
    "checkpoint = tf.train.Checkpoint(model=model)\n",
    "manager = tf.train.CheckpointManager(checkpoint,\n",
    "                                     directory='./saved/models',\n",
    "                                     checkpoint_name='model.ckpt',\n",
    "                                     max_to_keep=4)\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(f\"Epoch {epoch} :\")\n",
    "\n",
    "    print(\"Starting Training\")\n",
    "    for idx, data_batch in tqdm(enumerate(train_data)):\n",
    "        inputs, labels, labels_ws = data_batch\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            preds = model(inputs)\n",
    "            loss = loss_fn(labels, preds, sample_weight=labels_ws)\n",
    "        grads = tape.gradient(loss, model.variables)\n",
    "        optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
    "\n",
    "        if (idx + 1) % 200 == 0:\n",
    "            labels = np.argmax(labels, axis=-1)\n",
    "            preds = np.argmax(preds, axis=-1)\n",
    "\n",
    "            f1, acc = 0, 0\n",
    "            f1_details, acc_details = [], []\n",
    "            for col_idx in range(aspect_nums):\n",
    "                crt_f1 = f1_score(labels[:, col_idx],\n",
    "                                  preds[:, col_idx],\n",
    "                                  average=None)\n",
    "                crt_mean_f1 = np.mean(crt_f1)\n",
    "\n",
    "                crt_acc = accuracy_score(labels[:, col_idx], preds[:, col_idx])\n",
    "\n",
    "                f1_details.append(crt_mean_f1)\n",
    "                f1 += crt_mean_f1\n",
    "\n",
    "                acc_details.append(crt_acc)\n",
    "                acc += crt_acc\n",
    "            f1 = f1 / aspect_nums\n",
    "            acc = acc / aspect_nums\n",
    "            f1_details = np.round(f1_details, 3)\n",
    "            acc_details = np.round(acc_details, 3)\n",
    "\n",
    "            print(f\"Epoch {epoch}, Step {idx+1} on Training :\")\n",
    "            print(f\"Traning Loss : {loss.numpy()}\")\n",
    "            print('Total_f1={},\\n f1_details={}'.format(f1, f1_details))\n",
    "            print('Total_acc={},\\n acc_details={}'.format(acc, acc_details))\n",
    "            print()\n",
    "\n",
    "    print('--' * 40)\n",
    "    print(\"Starting Validation:\")\n",
    "    f1_details, acc_details = [0] * aspect_nums, [0] * aspect_nums\n",
    "    for idx, data_batch in tqdm(enumerate(val_data)):\n",
    "        inputs, labels, labels_ws = data_batch\n",
    "\n",
    "        preds = model(inputs)\n",
    "        loss = loss_fn(labels, preds, sample_weight=labels_ws)\n",
    "\n",
    "        labels = np.argmax(labels, axis=-1)\n",
    "        preds = np.argmax(preds, axis=-1)\n",
    "\n",
    "        for col_idx in range(aspect_nums):\n",
    "            crt_f1 = f1_score(labels[:, col_idx],\n",
    "                              preds[:, col_idx],\n",
    "                              average=None)\n",
    "            crt_mean_f1 = np.mean(crt_f1)\n",
    "\n",
    "            crt_acc = accuracy_score(labels[:, col_idx], preds[:, col_idx])\n",
    "\n",
    "            f1_details[col_idx] += crt_mean_f1\n",
    "\n",
    "            acc_details[col_idx] += crt_acc\n",
    "\n",
    "    f1_details = (np.array(f1_details) / (idx + 1)).round(3)\n",
    "    f1 = np.mean(f1_details)\n",
    "\n",
    "    acc_details = (np.array(acc_details) / (idx + 1)).round(3)\n",
    "    acc = np.mean(acc)\n",
    "\n",
    "    print(f\"Epoch {epoch}, on Validation :\")\n",
    "    print('Total_f1={}, \\n f1_details={}'.format(f1, f1_details))\n",
    "    print('Total_acc={}, \\n acc_details={}'.format(acc, acc_details))\n",
    "    \n",
    "    manager.save()\n",
    "\n",
    "    print(\"==\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T11:53:37.497915Z",
     "start_time": "2020-06-13T11:53:37.482730Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.AspectCNN at 0x7f532ccfc950>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AspectCNN(word_embed, aspect_input)\n",
    "checkpoint = tf.train.Checkpoint(model=model) # 键名一样\n",
    "checkpoint.restore(tf.train.latest_checkpoint('./saved/models'))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T11:53:52.232129Z",
     "start_time": "2020-06-13T11:53:52.219720Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected a TensorFlow function to generate a signature for, but got {'call', <tensorflow.python.eager.def_function.Function object at 0x7f532ccfce50>}. Only `tf.functions` with an input signature or concrete functions can be used as a signature.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-240-e44f3e7805ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"dianping_classifier\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"call\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m   _, exported_graph, object_saver, asset_info = _build_meta_graph(\n\u001b[0;32m--> 951\u001b[0;31m       obj, export_dir, signatures, options, meta_graph_def)\n\u001b[0m\u001b[1;32m    952\u001b[0m   \u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model_schema_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_SCHEMA_VERSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph\u001b[0;34m(obj, export_dir, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m   signatures, wrapped_functions = (\n\u001b[0;32m-> 1011\u001b[0;31m       signature_serialization.canonicalize_signatures(signatures))\n\u001b[0m\u001b[1;32m   1012\u001b[0m   \u001b[0msignature_serialization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_saveable_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_graph_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m   \u001b[0msignature_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature_serialization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_signature_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/saved_model/signature_serialization.py\u001b[0m in \u001b[0;36mcanonicalize_signatures\u001b[0;34m(signatures)\u001b[0m\n\u001b[1;32m    110\u001b[0m           (\"Expected a TensorFlow function to generate a signature for, but \"\n\u001b[1;32m    111\u001b[0m            \u001b[0;34m\"got {}. Only `tf.functions` with an input signature or \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m            \"concrete functions can be used as a signature.\").format(function))\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     wrapped_functions[original_function] = signature_function = (\n",
      "\u001b[0;31mValueError\u001b[0m: Expected a TensorFlow function to generate a signature for, but got {'call', <tensorflow.python.eager.def_function.Function object at 0x7f532ccfce50>}. Only `tf.functions` with an input signature or concrete functions can be used as a signature."
     ]
    }
   ],
   "source": [
    "import os\n",
    "model_version = \"0001\"\n",
    "model_name = \"dianping_classifier\"\n",
    "model_path = os.path.join(model_name, model_version)\n",
    "tf.saved_model.save(model, model_path, signatures={\"call\", model.call})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T09:33:20.880713Z",
     "start_time": "2020-06-13T09:33:19.630244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given SavedModel contains the following tag-sets:\r\n",
      "'serve'\r\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir {model_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T09:33:24.053655Z",
     "start_time": "2020-06-13T09:33:22.793209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given SavedModel MetaGraphDef contains SignatureDefs with the following keys:\r\n",
      "SignatureDef key: \"__saved_model_init_op\"\r\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir {model_path} --tag_set serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T07:08:13.574789Z",
     "start_time": "2020-06-13T07:08:12.319187Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\r\n",
      "\r\n",
      "signature_def['__saved_model_init_op']:\r\n",
      "  The given SavedModel SignatureDef contains the following input(s):\r\n",
      "  The given SavedModel SignatureDef contains the following output(s):\r\n",
      "    outputs['__saved_model_init_op'] tensor_info:\r\n",
      "        dtype: DT_INVALID\r\n",
      "        shape: unknown_rank\r\n",
      "        name: NoOp\r\n",
      "  Method name is: \r\n",
      "\r\n",
      "Defined Functions:"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir {model_path} --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T12:22:09.208749Z",
     "start_time": "2020-06-13T12:22:09.205804Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T12:22:09.937935Z",
     "start_time": "2020-06-13T12:22:09.931347Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(100, activation='relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(5, activation='softmax')        \n",
    "        \n",
    "    @tf.function(input_signature=[tf.TensorSpec([None, 28, 28, 1], tf.float32)])\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        x = tf.reshape(inputs, [inputs.shape[0], -1])\n",
    "        x = self.dense1(x)\n",
    "        y = self.dense2(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T12:22:11.628353Z",
     "start_time": "2020-06-13T12:22:11.466889Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    <ipython-input-29-cf20a7858b98>:10 call  *\n        x = tf.reshape(inputs, [inputs.shape[0], -1])\n    /home/yangbin7/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:193 reshape  **\n        result = gen_array_ops.reshape(tensor, shape, name)\n    /home/yangbin7/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py:8087 reshape\n        \"Reshape\", tensor=tensor, shape=shape, name=name)\n    /home/yangbin7/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:473 _apply_op_helper\n        raise err\n    /home/yangbin7/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:470 _apply_op_helper\n        preferred_dtype=default_dtype)\n    /home/yangbin7/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1341 convert_to_tensor\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    /home/yangbin7/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py:321 _constant_tensor_conversion_function\n        return constant(v, dtype=dtype, name=name)\n    /home/yangbin7/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py:262 constant\n        allow_broadcast=True)\n    /home/yangbin7/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py:300 _constant_impl\n        allow_broadcast=allow_broadcast))\n    /home/yangbin7/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py:547 make_tensor_proto\n        \"supported type.\" % (type(values), values))\n\n    TypeError: Failed to convert object of type <class 'list'> to Tensor. Contents: [None, -1]. Consider casting elements to a supported type.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-66adf7580f91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmy_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 506\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mbound_method_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3297\u001b[0m     \u001b[0;31m# However, the replacer is still responsible for attaching self properly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3298\u001b[0m     \u001b[0;31m# TODO(mdan): Is it possible to do it here instead?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3299\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3300\u001b[0m   \u001b[0mweak_bound_method_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_method_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    <ipython-input-29-cf20a7858b98>:10 call  *\n        x = tf.reshape(inputs, [inputs.shape[0], -1])\n    /home/yangbin7/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:193 reshape  **\n        result = gen_array_ops.reshape(tensor, shape, name)\n    /home/yangbin7/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py:8087 reshape\n        \"Reshape\", tensor=tensor, shape=shape, name=name)\n    /home/yangbin7/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:473 _apply_op_helper\n        raise err\n    /home/yangbin7/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:470 _apply_op_helper\n        preferred_dtype=default_dtype)\n    /home/yangbin7/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1341 convert_to_tensor\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    /home/yangbin7/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py:321 _constant_tensor_conversion_function\n        return constant(v, dtype=dtype, name=name)\n    /home/yangbin7/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py:262 constant\n        allow_broadcast=True)\n    /home/yangbin7/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py:300 _constant_impl\n        allow_broadcast=allow_broadcast))\n    /home/yangbin7/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py:547 make_tensor_proto\n        \"supported type.\" % (type(values), values))\n\n    TypeError: Failed to convert object of type <class 'list'> to Tensor. Contents: [None, -1]. Consider casting elements to a supported type.\n"
     ]
    }
   ],
   "source": [
    "my_model = MyModel()\n",
    "\n",
    "inputs = tf.random.uniform([3, 28, 28, 1])\n",
    "my_model(inputs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T12:05:34.940959Z",
     "start_time": "2020-06-13T12:05:34.804006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yangbin7/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: jjjj/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(my_model, \"jjjj\", signatures={\"call\": my_model.call})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T12:06:00.040691Z",
     "start_time": "2020-06-13T12:05:58.767469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['call']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['inputs'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 28, 28, 1)\n",
      "        name: call_inputs:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['output_0'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 5)\n",
      "        name: StatefulPartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n",
      "WARNING:tensorflow:From /home/yangbin7/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "\n",
      "Defined Functions:\n",
      "  Function Name: '__call__'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
      "\n",
      "  Function Name: '_default_save_signature'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          args_0: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='args_0')\n",
      "\n",
      "  Function Name: 'call'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
      "\n",
      "  Function Name: 'call_and_return_all_conditional_losses'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir \"jjjj\" --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "1132.5px",
    "left": "831px",
    "right": "20px",
    "top": "120px",
    "width": "229px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
